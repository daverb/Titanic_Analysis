{
 "metadata": {
  "name": "",
  "signature": "sha256:0fa0878cacf304106d1f68d7f14a8861ebcf3f4e206e4cb729e8cefc99d5815d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\" Writing my first randomforest code.\n",
      "Author : AstroDave\n",
      "Date : 23rd September 2012\n",
      "Revised: 15 April 2014\n",
      "please see packages.python.org/milk/randomforests.html for more\n",
      "\n",
      "\"\"\"\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import csv as csv\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "\n",
      "# Data cleanup\n",
      "# TRAIN DATA\n",
      "train_df = pd.read_csv('train.csv', header=0)        # Load the train file into a dataframe\n",
      "\n",
      "# I need to convert all strings to integer classifiers.\n",
      "# I need to fill in the missing values of the data and make it complete.\n",
      "\n",
      "# female = 0, Male = 1\n",
      "train_df['Gender'] = train_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
      "\n",
      "# Embarked from 'C', 'Q', 'S'\n",
      "# Note this is not ideal: in translating categories to numbers, Port \"2\" is not 2 times greater than Port \"1\", etc.\n",
      "\n",
      "# All missing Embarked -> just make them embark from most common place\n",
      "if len(train_df.Embarked[ train_df.Embarked.isnull() ]) > 0:\n",
      "    train_df.Embarked[ train_df.Embarked.isnull() ] = train_df.Embarked.dropna().mode().values\n",
      "\n",
      "Ports = list(enumerate(np.unique(train_df['Embarked'])))    # determine all values of Embarked,\n",
      "Ports_dict = { name : i for i, name in Ports }              # set up a dictionary in the form  Ports : index\n",
      "train_df.Embarked = train_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)     # Convert all Embark strings to int\n",
      "\n",
      "# All the ages with no data -> make the median of all Ages\n",
      "median_age = train_df['Age'].dropna().median()\n",
      "if len(train_df.Age[ train_df.Age.isnull() ]) > 0:\n",
      "    train_df.loc[ (train_df.Age.isnull()), 'Age'] = median_age\n",
      "\n",
      "# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\n",
      "train_df = train_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
      "\n",
      "\n",
      "# TEST DATA\n",
      "test_df = pd.read_csv('test.csv', header=0)        # Load the test file into a dataframe\n",
      "\n",
      "# I need to do the same with the test data now, so that the columns are the same as the training data\n",
      "# I need to convert all strings to integer classifiers:\n",
      "# female = 0, Male = 1\n",
      "test_df['Gender'] = test_df['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
      "\n",
      "# Embarked from 'C', 'Q', 'S'\n",
      "# All missing Embarked -> just make them embark from most common place\n",
      "if len(test_df.Embarked[ test_df.Embarked.isnull() ]) > 0:\n",
      "    test_df.Embarked[ test_df.Embarked.isnull() ] = test_df.Embarked.dropna().mode().values\n",
      "# Again convert all Embarked strings to int\n",
      "test_df.Embarked = test_df.Embarked.map( lambda x: Ports_dict[x]).astype(int)\n",
      "\n",
      "\n",
      "# All the ages with no data -> make the median of all Ages\n",
      "median_age = test_df['Age'].dropna().median()\n",
      "if len(test_df.Age[ test_df.Age.isnull() ]) > 0:\n",
      "    test_df.loc[ (test_df.Age.isnull()), 'Age'] = median_age\n",
      "\n",
      "# All the missing Fares -> assume median of their respective class\n",
      "if len(test_df.Fare[ test_df.Fare.isnull() ]) > 0:\n",
      "    median_fare = np.zeros(3)\n",
      "    for f in range(0,3):                                              # loop 0 to 2\n",
      "        median_fare[f] = test_df[ test_df.Pclass == f+1 ]['Fare'].dropna().median()\n",
      "    for f in range(0,3):                                              # loop 0 to 2\n",
      "        test_df.loc[ (test_df.Fare.isnull()) & (test_df.Pclass == f+1 ), 'Fare'] = median_fare[f]\n",
      "\n",
      "# Collect the test data's PassengerIds before dropping it\n",
      "ids = test_df['PassengerId'].values\n",
      "# Remove the Name column, Cabin, Ticket, and Sex (since I copied and filled it to Gender)\n",
      "test_df = test_df.drop(['Name', 'Sex', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
      "\n",
      "\n",
      "# The data is now ready to go. So lets fit to the train, then predict to the test!\n",
      "# Convert back to a numpy array\n",
      "train_data = train_df.values\n",
      "test_data = test_df.values\n",
      "\n",
      "\n",
      "print ('Training...')\n",
      "forest = RandomForestClassifier(n_estimators=100)\n",
      "forest = forest.fit( train_data[0::,1::], train_data[0::,0] )\n",
      "\n",
      "print ('Predicting...')\n",
      "output = forest.predict(test_data).astype(int)\n",
      "\n",
      "\n",
      "predictions_file = open(\"myfirstforest.csv\", \"wb\")\n",
      "open_file_object = csv.writer(predictions_file)\n",
      "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
      "open_file_object.writerows(zip(ids, output))\n",
      "predictions_file.close()\n",
      "print ('Done.')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training...\n",
        "Predicting..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "'str' does not support the buffer interface",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-ff78ef8ff530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mpredictions_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"myfirstforest.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0mopen_file_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mopen_file_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0mopen_file_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mpredictions_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'str' does not support the buffer interface"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}